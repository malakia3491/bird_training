# Анализ результатов SSL обучения

## Результаты оценки

| Метод | Train Accuracy | Test Accuracy |
|-------|----------------|---------------|
| Linear Probe | 99.99% | **1.06%** |
| kNN (k=20) | 9.07% | **0.67%** |

Random baseline для 397 классов = ~0.25%

---

## Основные причины низкой точности

### 1. Контрастивное обучение НЕ учит семантику

SSL с NT-Xent loss учит модель различать **"это один и тот же файл"** vs **"это разные файлы"**.

Модель научилась отличать записи по:
- Качеству записи
- Фоновому шуму
- Громкости
- Микрофону

А **НЕ по виду птицы**! Две записи одной и той же птицы для модели — это просто "разные файлы".

### 2. Train loss 0.05 — это "слишком хорошо"

Когда contrastive loss падает очень низко, это часто признак **коллапса** — модель нашла shortcut (ярлык), который не связан с полезными признаками.

### 3. Linear probe не работает для таких случаев

При коллапсе эмбеддинги всех птиц могут быть очень похожи друг на друга, поэтому линейный классификатор не может их разделить.

---

## Проблема простыми словами

**SimCLR учит модель отвечать на вопрос:**
> "Это две версии ОДНОГО файла или РАЗНЫХ файлов?"

**А нужно чтобы модель отвечала на вопрос:**
> "Какая это птица?"

---

Модель научилась различать **записи**, а не **птиц**.

Пример:
- Запись_1 синицы и Запись_2 синицы → для модели это **разные** объекты
- Запись_1 синицы + шум и Запись_1 синицы + кроп → для модели это **одинаковые** объекты

То есть модель группирует по **"какой это файл"**, а не по **"какая это птица"**.

---

## Что делать?

### Вариант 1: Fine-tuning (дообучение всей модели)

```bash
# Конвертируй веса
python scripts/convert_ssl_ckpt.py --ckpt outputs/.../last.ckpt --output ssl_init.pth

# И запусти обычное supervised обучение с ними как инициализацией
```

### Вариант 2: Попробовать другой SSL метод

- **BYOL / SimSiam** — не требуют negative samples, менее склонны к коллапсу
- **DINO** — работает лучше на мелких различиях
- **SupCon (Supervised Contrastive)** — использует метки классов, группирует записи одного класса вместе

### Вариант 3: Сразу supervised обучение

Если есть метки для 397 классов — лучше сразу supervised обучение без SSL предобучения.

---

## Итог

SSL предобучение в виде SimCLR не помогает для классификации птиц, потому что модель учится различать **файлы**, а не **классы птиц**.

---

# Рекомендации: что делать дальше

## Наиболее вероятно поможет (в порядке приоритета)

### 1. Supervised обучение напрямую (самый надёжный вариант)

Если есть метки для 397 классов — SSL предобучение не нужно. Просто обучай классификатор напрямую.

**Почему это лучше:**
- Модель сразу учится отличать птиц
- Нет риска коллапса
- Проще отлаживать

```bash
python train.py  # обычное supervised обучение
```

---

### 2. Supervised Contrastive Learning (SupCon)

Если хочется контрастивное обучение — используй **SupCon** вместо SimCLR.

**Разница:**
- SimCLR: "Это один файл или разные файлы?"
- SupCon: "Это одна птица или разные птицы?"

SupCon использует метки классов, чтобы:
- Сближать ВСЕ записи одного класса птицы
- Отдалять записи разных классов

**Реализация:**
```python
# SupCon Loss (Supervised Contrastive)
# Позитивные пары = все записи одного класса в батче
# Негативные пары = записи других классов

class SupConLoss(nn.Module):
    def __init__(self, temperature=0.07):
        super().__init__()
        self.temperature = temperature

    def forward(self, features, labels):
        # features: (B, D) - нормализованные эмбеддинги
        # labels: (B,) - метки классов

        device = features.device
        batch_size = features.shape[0]

        # Маска позитивных пар (одинаковый класс)
        labels = labels.view(-1, 1)
        mask = torch.eq(labels, labels.T).float().to(device)

        # Cosine similarity
        similarity = torch.matmul(features, features.T) / self.temperature

        # Убираем диагональ
        logits_mask = torch.ones_like(mask) - torch.eye(batch_size, device=device)
        mask = mask * logits_mask

        # Log-softmax
        exp_logits = torch.exp(similarity) * logits_mask
        log_prob = similarity - torch.log(exp_logits.sum(1, keepdim=True))

        # Среднее по позитивным парам
        mean_log_prob = (mask * log_prob).sum(1) / mask.sum(1).clamp(min=1)
        loss = -mean_log_prob.mean()

        return loss
```

**Важно:** Нужен большой batch size (256+), чтобы в батче было несколько записей каждого класса.

---

### 3. Fine-tuning текущих SSL весов

Если хочется использовать уже обученные SSL веса:

```bash
# 1. Конвертируй веса backbone
python scripts/convert_ssl_ckpt.py \
    --ckpt outputs/2025-12-19/22-53-45/checkpoints/last.ckpt \
    --output ssl_backbone.pth

# 2. В конфиге модели укажи checkpoint_path
# configs/model/efficientnet.yaml:
#   checkpoint_path: ssl_backbone.pth

# 3. Запусти supervised обучение
python train.py
```

**Важно:** Не замораживай backbone — дообучай всю модель целиком.

---

## Что НЕ поможет

1. **Больше эпох SSL** — модель уже сошлась (loss 0.05), больше эпох не изменят ситуацию
2. **Другие аугментации** — проблема не в аугментациях, а в самой задаче SimCLR
3. **Linear probe** — при коллапсе представлений линейный классификатор бесполезен

---

## Вывод

**Рекомендация:** Используй supervised обучение напрямую или SupCon если хочется контрастивный подход.

SimCLR хорошо работает для задач, где нужно выучить общие визуальные признаки (например, предобучение на ImageNet). Но для специфичной задачи классификации птиц по звуку — лучше сразу использовать метки.

---

# SSL подходы: что реально работает

Если нужен именно SSL (без supervised), вот варианты в порядке приоритета:

## 1. SupCon (Supervised Contrastive) — лучший вариант

**Идея:** Контрастивное обучение, но с метками. Сближает все записи одного класса.

**Преимущества:**
- Использует метки, но учит эмбеддинги, а не классификатор
- Эмбеддинги переносятся на новые классы (few-shot learning)
- Нет проблемы коллапса

**Нужно:**
- Большой batch size (256+), чтобы в батче было несколько записей каждого класса
- Или использовать memory bank для накопления эмбеддингов

---

## 2. BYOL / SimSiam — без negative samples

**Идея:** Учимся предсказывать один view из другого без negative samples.

**Преимущества:**
- Не нужен большой batch size
- Нет коллапса (при правильной реализации)
- Проще в настройке

**BYOL архитектура:**
```
view1 → encoder → projector → predictor → z1
view2 → encoder → projector ────────────→ z2 (stop gradient!)

loss = MSE(z1, z2.detach())
```

**Ключевой момент:** stop_gradient на target network + EMA update весов.

---

## 3. DINO — self-distillation

**Идея:** Student учится у Teacher (EMA копии себя) через softmax centering.

**Преимущества:**
- Очень стабильный
- Хорошо работает с Vision Transformers
- Учит семантические признаки

**Минусы:**
- Сложнее в реализации
- Требует больше вычислений

---

## 4. Улучшенный SimCLR

Если хочется остаться на SimCLR, можно попробовать:

### a) Увеличить batch size
```yaml
# Текущий: batch=32, accumulate=8 → effective=256
# Нужно: batch=64, accumulate=16 → effective=1024+
batch_size: 64
accumulate_grad_batches: 16
```

Больше negative samples = лучше контраст.

### b) Поднять temperature
```yaml
# Текущий: 0.1 (слишком низкий)
# Попробовать: 0.5 или 0.07
temperature: 0.5
```

### c) Multi-crop стратегия
Использовать несколько кропов разного размера:
- 2 больших кропа (224x224)
- 4-6 маленьких кропов (96x96)

Это даёт больше positive pairs без увеличения batch size.

### d) Аугментации специфичные для аудио птиц
```python
# Добавить:
- Pitch shift (смещение частоты пения)
- Time stretch (замедление/ускорение)
- Mixing разных записей одной птицы (если есть метки)
- Background noise из других записей
```

---

## Рекомендуемый план действий

### Шаг 1: Попробовать SupCon (если есть метки хотя бы для части данных)

Это даст лучшие эмбеддинги для классификации птиц.

### Шаг 2: Если нет меток — BYOL/SimSiam

Они более стабильны чем SimCLR и не требуют огромного batch size.

### Шаг 3: Увеличить batch size для SimCLR

Если хочется остаться на SimCLR — нужен batch 1024+ для хороших результатов.

---

## Что реализовать

Рекомендую добавить **SupCon Loss** — это минимальное изменение текущего кода:

1. Датасет уже возвращает метки (просто игнорируются)
2. Loss меняется с NTXent на SupCon
3. Остальное остаётся как есть

Второй вариант — **BYOL**, но там нужно добавить:
- Predictor MLP
- Target network (EMA копия encoder)
- Другой loss (MSE вместо contrastive)
