import hydra
from omegaconf import DictConfig
import pytorch_lightning as pl
import os
import torch
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.loggers import CSVLogger # <--- –ù–æ–≤—ã–π –∏–º–ø–æ—Ä—Ç

# –ò–º–ø–æ—Ä—Ç instantiate –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
from hydra.utils import instantiate

from src.system import BirdClassifier
from src.utils.reporter import ExperimentReporter

@hydra.main(config_path="configs", config_name="train_config", version_base="1.3")
def main(cfg: DictConfig):
    pl.seed_everything(42)

    # 0. –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ outputs (–∫–æ—Ç–æ—Ä—É—é —Å–æ–∑–¥–∞–ª–∞ Hydra)
    # –≠—Ç–æ –ø–∞–ø–∫–∞ –≤–∏–¥–∞: outputs/2025-12-14/19-45-00
    output_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir
    print(f"üìÇ –†–∞–±–æ—á–∞—è –ø–∞–ø–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {output_dir}")

    # 1. –î–∞–Ω–Ω—ã–µ
    dm = instantiate(cfg.data)
    dm.setup()
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∫–ª–∞—Å—Å–æ–≤
    cfg.model.num_classes = dm.num_classes
    
    # 2. –ú–æ–¥–µ–ª—å
    model = BirdClassifier(cfg)

    # 3. –õ–æ–≥–≥–µ—Ä (—á—Ç–æ–±—ã –Ω–µ —Å–æ–∑–¥–∞–≤–∞–ª–∞—Å—å –ø–∞–ø–∫–∞ lightning_logs –≤ –∫–æ—Ä–Ω–µ)
    # save_dir=output_dir -> –ª–æ–≥–∏ —É–ø–∞–¥—É—Ç –≤–Ω—É—Ç—Ä—å –ø–∞–ø–∫–∏ Hydra
    # name="logs" -> –ø–æ–¥–ø–∞–ø–∫–∞ logs
    # version="" -> –Ω–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å version_0, version_1...
    logger = CSVLogger(save_dir=output_dir, name="logs", version="")

    # 4. Callbacks
    # –ß–µ–∫–ø–æ–∏–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º —è–≤–Ω–æ –≤ output_dir/checkpoints
    checkpoint_callback = ModelCheckpoint(
        dirpath=os.path.join(output_dir, "checkpoints"), # <--- –Ø–≤–Ω—ã–π –ø—É—Ç—å
        monitor='val_loss',
        filename='{epoch}-{val_loss:.4f}',
        save_top_k=1,
        mode='min',
    )
    
    # –ù–∞—à —Ä–µ–ø–æ—Ä—Ç–µ—Ä
    reporter = ExperimentReporter(cfg, output_dir)

    # 5. –¢—Ä–µ–π–Ω–µ—Ä
    trainer = pl.Trainer(
        max_epochs=cfg.trainer.max_epochs,
        accelerator=cfg.trainer.accelerator,
        devices=cfg.trainer.devices,
        precision=cfg.trainer.precision,
        callbacks=[checkpoint_callback, reporter],
        logger=logger, # <--- –ü–æ–¥–∫–ª—é—á–∞–µ–º –Ω–∞—à –ª–æ–≥–≥–µ—Ä
        log_every_n_steps=cfg.trainer.log_every_n_steps
    )

    # 6. –û–±—É—á–µ–Ω–∏–µ
    trainer.fit(model, dm)

if __name__ == "__main__":
    main()