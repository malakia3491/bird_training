import torch
import pytorch_lightning as pl
import pandas as pd
from hydra.utils import instantiate
from omegaconf import OmegaConf
import os
import shutil

CKPT_PATH = "D:/coding/source/dissertation/bird_training/outputs/2025-12-17/20-36-11/checkpoints/epoch=15-val_loss=0.3166.ckpt"
DATA_ROOT = "D:/coding/data/birds_common/data_russian" 

def main():
    print(f"üîç Loading Checkpoint: {CKPT_PATH}")
    
    if not os.path.exists(CKPT_PATH):
        raise FileNotFoundError(f"Checkpoint not found: {CKPT_PATH}")
        
    checkpoint = torch.load(CKPT_PATH, map_location="cpu", weights_only=False)
    cfg = checkpoint['hyper_parameters']['cfg']
    cfg.data.root_dir = DATA_ROOT
    
    # --- –•–ê–ö –î–õ–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –ú–ï–¢–û–ö ---
    # –ú—ã –≤—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π label_encoder.pkl, —á—Ç–æ–±—ã DataModule –Ω–µ –Ω–∞—à–µ–ª –µ–≥–æ
    # –∏ —Å–æ–∑–¥–∞–ª –Ω–æ–≤—ã–π, –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —ç–Ω–∫–æ–¥–µ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ CSV —Ñ–∞–π–ª–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.
    
    encoder_path = os.path.join(DATA_ROOT, 'checkpoints', 'label_encoder.pkl')
    temp_encoder_path = os.path.join(DATA_ROOT, 'checkpoints', 'label_encoder.pkl.bak')
    renamed = False
    
    if os.path.exists(encoder_path):
        print("‚ö†Ô∏è Found existing LabelEncoder. Hiding it to force clean regeneration...")
        try:
            os.rename(encoder_path, temp_encoder_path)
            renamed = True
        except OSError:
            print("‚ùå Cannot rename LabelEncoder (file used?). Logic might fail.")

    try:
        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        print("üì¶ Initializing DataModule (Rebuilding Encoder)...")
        from src.data_loaders.bird_datamodule import BirdDataModule
        
        dm = BirdDataModule(
            root_dir=cfg.data.root_dir,
            batch_size=cfg.data.batch_size,
            num_workers=cfg.data.num_workers,
            resize_shape=cfg.data.get('resize_shape', None)
        )
        dm.setup()
        
        # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
        print(f"üß† Initializing Model (Num Classes in Config: {cfg.model.num_classes})...")
        print(f"   Num Classes in Data: {dm.num_classes}")
        
        if dm.num_classes != cfg.model.num_classes:
            print("üö® WARNING: Mismatch in class count! Model might fail.")
        
        from src.system import BirdClassifier
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–ª–∞—Å—Å–∞
        if 'head' in cfg and 'ArcFace' in cfg.head.get('_target_', ''):
            from src.system_metric import MetricLearningSystem
            model_cls = MetricLearningSystem
        else:
            model_cls = BirdClassifier

        model = model_cls(cfg)
        model.load_state_dict(checkpoint['state_dict'])
        model.eval()
        
        # 4. –¢—Ä–µ–π–Ω–µ—Ä
        trainer = pl.Trainer(accelerator="gpu", devices=1, logger=False)

        # 5. –§—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏
        results = {}

        def evaluate_split(split_name, dataloader):
            if dataloader is None or len(dataloader) == 0:
                print(f"‚ö†Ô∏è  Skipping {split_name}: DataLoader is empty.")
                return None
            print(f"\nüöÄ Testing on {split_name} Set...")
            metrics_list = trainer.test(model, dataloaders=dataloader, verbose=False)
            metrics = metrics_list[0]
            clean_metrics = {k.replace('test_', ''): v for k, v in metrics.items()}
            return clean_metrics

        # --- –ó–ê–ü–£–°–ö ---
        results['Test'] = evaluate_split('Test', dm.test_dataloader())
        results['Val'] = evaluate_split('Validation', dm.val_dataloader())
        # Train –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏, –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω
        results['Train'] = evaluate_split('Train', dm.train_dataloader())

        # --- –í–´–í–û–î ---
        print("\n" + "="*60)
        print(f"üìä FINAL REPORT: {cfg.project_name}")
        print("="*60)
        
        df_data = []
        metric_names = ['loss', 'f1', 'acc', 'precision', 'recall']
        
        for split_name, res in results.items():
            if res is None: continue
            row = {'Split': split_name}
            for m in metric_names:
                val = "N/A"
                for k, v in res.items():
                    if m in k:
                        val = f"{v:.4f}"
                        break
                row[m.capitalize()] = val
            df_data.append(row)

        df = pd.DataFrame(df_data)
        print(df.to_string(index=False))
        print("="*60)
        
        output_csv = "final_metrics_verification.csv"
        df.to_csv(output_csv, index=False)
        print(f"Saved to {output_csv}")

    finally:
        # –í–û–ó–í–†–ê–©–ê–ï–ú –§–ê–ô–õ –ù–ê –ú–ï–°–¢–û
        if renamed and os.path.exists(temp_encoder_path):
            print("Restoring original LabelEncoder file...")
            if os.path.exists(encoder_path):
                os.remove(encoder_path) # –£–¥–∞–ª—è–µ–º —Ç–æ—Ç, —á—Ç–æ —Å–æ–∑–¥–∞–ª–∏ —Å–µ–π—á–∞—Å
            os.rename(temp_encoder_path, encoder_path)

if __name__ == "__main__":
    main()